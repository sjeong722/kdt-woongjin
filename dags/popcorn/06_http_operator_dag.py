import pendulum
from airflow import DAG
from airflow.decorators import task
from airflow.operators.python import get_current_context
import pandas as pd
from pprint import pprint
from airflow.providers.http.operators.http import HttpOperator
"""
ðŸ”¸ HttpOperator
    - ì§€ì •ëœ HTTP ì—”ë“œí¬ì¸íŠ¸ë¡œ ìš”ì²­ì„ ë³´ë‚´ê³  ê·¸ ì‘ë‹µì„ ê°€ì ¸ì˜¤ëŠ” ìž‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì˜¤í¼ë ˆì´í„°
    - Airflow UIì—ì„œ 'HTTP' connection ì„¤ì • í•„ìš”!

ðŸ”¸ Connection ì„¤ì • ì •ë³´
    - Conn Id : http_connection
    - Host : https://fakerapi.it/api/v2
    
https://airflow.apache.org/docs/apache-airflow-providers-http/stable/_api/airflow/providers/http/operators/http/index.html
"""

default_args = dict(
    owner = 'popcorn',
    email = ['datapopcorn@gmail.com'],
    email_on_failure = False,
    retries = 3
    )

with DAG(
    dag_id="06_http_operator_dag",
    start_date=pendulum.datetime(2025, 8, 1, tz='Asia/Seoul'),
    schedule="30 10 * * *",
    default_args = default_args,
    catchup=False
):
    get_api_data = HttpOperator(
        task_id='get_api_data',
        http_conn_id='http_connection',
        method='GET',
        endpoint='users',
        response_filter=lambda response: response.json()['data']
    )
    
    @task(task_id='api_to_dataframe')
    def api_to_dataframe():
        
        # XCOM ì €ìž¥ì†Œì— ì €ìž¥ëœ API ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œ
        context = get_current_context()
        ti = context['ti']
        api_data = ti.xcom_pull(task_ids='get_api_data')
        
        # ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.json_normalize(api_data)
        
        for row in df.head().to_dict(orient='records'):
            pprint(row)
        print("df.shape : ", df.shape)
        
get_api_data >> api_to_dataframe()